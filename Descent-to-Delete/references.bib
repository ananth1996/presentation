@article{JMLR:v14:zhang13b,
  author  = {Yuchen Zhang and John C. Duchi and Martin J. Wainwright},
  title   = {Communication-Efficient Algorithms for Statistical Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  number  = {68},
  pages   = {3321-3363},
  url     = {http://jmlr.org/papers/v14/zhang13b.html}
}

@article{wuDeltaGradRapidRetraining2020,
  title = {{{DeltaGrad}}: {{Rapid}} Retraining of Machine Learning Models},
  shorttitle = {{{DeltaGrad}}},
  author = {Wu, Yinjun and Dobriban, Edgar and Davidson, Susan B.},
  year = {2020},
  month = jun,
  abstract = {Machine learning models are not static and may need to be retrained on slightly changed datasets, for instance, with the addition or deletion of a set of data points. This has many applications, including privacy, robustness, bias reduction, and uncertainty quantifcation. However, it is expensive to retrain models from scratch. To address this problem, we propose the DeltaGrad algorithm for rapid retraining machine learning models based on information cached during the training phase. We provide both theoretical and empirical support for the effectiveness of DeltaGrad, and show that it compares favorably to the state of the art.},
  archiveprefix = {arXiv},
  eprint = {2006.14755},
  eprinttype = {arxiv},
  file = {/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/DeltaGrad/Slides.pdf;/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/DeltaGrad/Wu et al_2020_DeltaGrad_annotated.pdf;/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/DeltaGrad/Wu et al_2020_DeltaGrad.pdf;/Users/mahadeva/Zotero/storage/RXXIBZYK/2006.html},
  journal = {arXiv:2006.14755 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{guoCertifiedDataRemoval2020,
  title = {Certified {{Data Removal}} from {{Machine Learning Models}}},
  author = {Guo, Chuan and Goldstein, Tom and Hannun, Awni and {van der Maaten}, Laurens},
  year = {2020},
  month = aug,
  abstract = {Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to "remove" data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.},
  archiveprefix = {arXiv},
  eprint = {1911.03030},
  eprinttype = {arxiv},
  file = {/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/Certified Data Removal from Machine Learning Models/Guo et al_2020_Certified Data Removal from Machine Learning Models_annotated.pdf;/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/Certified Data Removal from Machine Learning Models/Guo et al_2020_Certified Data Removal from Machine Learning Models.pdf},
  journal = {arXiv:1911.03030 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}
@inproceedings{caoMakingSystemsForget2015,
  title = {Towards {{Making Systems Forget}} with {{Machine Unlearning}}},
  booktitle = {2015 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  author = {Cao, Yinzhi and Yang, Junfeng},
  year = {2015},
  month = may,
  pages = {463--480},
  publisher = {{IEEE}},
  address = {{San Jose, CA}},
  doi = {10.1109/SP.2015.35},
  abstract = {Today's systems produce a rapidly exploding amount of data, and the data further derives more data, forming a complex data propagation network that we call the data's lineage. There are many reasons that users want systems to forget certain data including its lineage. From a privacy perspective, users who become concerned with new privacy risks of a system often want the system to forget their data and lineage. From a security perspective, if an attacker pollutes an anomaly detector by injecting manually crafted data into the training data set, the detector must forget the injected data to regain security. From a usability perspective, a user can remove noise and incorrect entries so that a recommendation engine gives useful recommendations. Therefore, we envision forgetting systems, capable of forgetting certain data and their lineages, completely and quickly.},
  file = {/Users/mahadeva/OneDrive - University of Helsinki/ZoteroAttachments/UpdateML/Towards Making Systems Forget with Machine Unlearning/Cao_Yang_2015_Towards Making Systems Forget with Machine Unlearning.pdf},
  isbn = {978-1-4673-6949-7},
  language = {en}
}